{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T15:09:49.510690Z",
     "start_time": "2025-09-29T15:09:45.839224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch, platform"
   ],
   "id": "2ffe3a669bad0a7d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3362, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3607, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/80/7528r6gs3fq0v7xq3xtq8zzc0000gn/T/ipykernel_7803/458336005.py\", line 1, in <module>\n",
      "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/transformers/__init__.py\", line 27, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/transformers/utils/__init__.py\", line 24, in <module>\n",
      "    from .auto_docstring import (\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/transformers/utils/auto_docstring.py\", line 30, in <module>\n",
      "    from .generic import ModelOutput\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/transformers/utils/generic.py\", line 51, in <module>\n",
      "    import torch  # noqa: F401\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T15:10:23.816778Z",
     "start_time": "2025-09-29T15:10:23.813582Z"
    }
   },
   "cell_type": "code",
   "source": "model_id = \"LiquidAI/LFM2-2.6B\"",
   "id": "a81ed76cd09c3994",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T15:10:25.113156Z",
     "start_time": "2025-09-29T15:10:25.069029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "device = \"mps\" if use_mps else \"cpu\""
   ],
   "id": "5a9ed07206943398",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T15:10:36.429870Z",
     "start_time": "2025-09-29T15:10:26.804734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dtype = torch.float16 if use_mps else torch.float32  # bfloat16 is often unsupported on MPS/CPU\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",            # needs accelerate\n",
    "    dtype=dtype,                  # replaces torch_dtype\n",
    "    low_cpu_mem_usage=True,\n",
    ")"
   ],
   "id": "5f0582a78f0b3ac9",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m dtype = torch.float16 \u001B[38;5;28;01mif\u001B[39;00m use_mps \u001B[38;5;28;01melse\u001B[39;00m torch.float32  \u001B[38;5;66;03m# bfloat16 is often unsupported on MPS/CPU\u001B[39;00m\n\u001B[32m      3\u001B[39m tok = AutoTokenizer.from_pretrained(model_id)\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m model = AutoModelForCausalLM.from_pretrained(\n\u001B[32m      5\u001B[39m     model_id,\n\u001B[32m      6\u001B[39m     device_map=\u001B[33m\"\u001B[39m\u001B[33mauto\u001B[39m\u001B[33m\"\u001B[39m,            \u001B[38;5;66;03m# needs accelerate\u001B[39;00m\n\u001B[32m      7\u001B[39m     dtype=dtype,                  \u001B[38;5;66;03m# replaces torch_dtype\u001B[39;00m\n\u001B[32m      8\u001B[39m     low_cpu_mem_usage=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m      9\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:604\u001B[39m, in \u001B[36m_BaseAutoModelClass.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[39m\n\u001B[32m    602\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m model_class.config_class == config.sub_configs.get(\u001B[33m\"\u001B[39m\u001B[33mtext_config\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    603\u001B[39m         config = config.get_text_config()\n\u001B[32m--> \u001B[39m\u001B[32m604\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m model_class.from_pretrained(\n\u001B[32m    605\u001B[39m         pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n\u001B[32m    606\u001B[39m     )\n\u001B[32m    607\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    608\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig.\u001B[34m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    609\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m, \u001B[39m\u001B[33m'\u001B[39m.join(c.\u001B[34m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m._model_mapping)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    610\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/transformers/modeling_utils.py:288\u001B[39m, in \u001B[36mrestore_default_dtype.<locals>._wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    286\u001B[39m old_dtype = torch.get_default_dtype()\n\u001B[32m    287\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m288\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m func(*args, **kwargs)\n\u001B[32m    289\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    290\u001B[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/local/Caskroom/miniforge/base/envs/Foodi_Agent/lib/python3.12/site-packages/transformers/modeling_utils.py:4933\u001B[39m, in \u001B[36mPreTrainedModel.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[39m\n\u001B[32m   4931\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mDeepSpeed Zero-3 is not compatible with passing a `device_map`.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   4932\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_accelerate_available():\n\u001B[32m-> \u001B[39m\u001B[32m4933\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   4934\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mUsing a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4935\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mrequires `accelerate`. You can install it with `pip install accelerate`\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4936\u001B[39m         )\n\u001B[32m   4938\u001B[39m \u001B[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001B[39;00m\n\u001B[32m   4939\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m load_in_4bit \u001B[38;5;129;01mor\u001B[39;00m load_in_8bit:\n",
      "\u001B[31mValueError\u001B[39m: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f58c7b8959a0892f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
